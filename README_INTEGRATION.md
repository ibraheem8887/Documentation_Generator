# Python Documentation Generation System - Phase 5 Integration

This is the complete integrated system that combines BPE tokenization, Word2Vec embeddings, and BiLSTM language model to automatically generate documentation for Python functions.

## ğŸ—ï¸ System Architecture

The system follows a unified pipeline:

1. **Input**: Python function code
2. **Step 1**: BPE tokenization for code preprocessing
3. **Step 2**: Word2Vec embeddings for semantic understanding (optional enhancement)
4. **Step 3**: BiLSTM language model generates docstring
5. **Output**: Complete documentation with summary and docstring

## ğŸ“ Project Structure

```
GenerativeAI_Project/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ pipeline.py           # Core unified pipeline
â”‚   â”œâ”€â”€ doc_generator.py      # Main documentation generator
â”‚   â””â”€â”€ test_integration.py   # Integration tests
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_app.py      # Web interface
â”œâ”€â”€ bpe/
â”‚   â”œâ”€â”€ bpe_tokenizer.py      # BPE tokenizer implementation
â”‚   â””â”€â”€ bpe_*.pkl             # Trained BPE models
â”œâ”€â”€ word2vec/
â”‚   â”œâ”€â”€ word2vec.py           # Word2Vec model
â”‚   â”œâ”€â”€ word2vec_model.pt     # Trained Word2Vec model
â”‚   â””â”€â”€ utils.py              # Word2Vec utilities
â”œâ”€â”€ bilstm/
â”‚   â”œâ”€â”€ bilstm_model.pt       # Trained BiLSTM model
â”‚   â””â”€â”€ bpe_tokenizer.pkl     # Tokenizer for BiLSTM
â””â”€â”€ data/
    â””â”€â”€ clean_dataset.csv     # Training dataset
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Test the Integration

```bash
cd integration
python test_integration.py
```

### 3. Run the Web Interface

```bash
cd ui
streamlit run streamlit_app.py
```

### 4. Command Line Usage

```bash
cd integration
python doc_generator.py "def example(x): return x * 2" -o output.md
```

## ğŸ’» Usage Examples

### Python API

```python
from integration.doc_generator import DocumentationGenerator

# Initialize generator
generator = DocumentationGenerator()

# Generate from code string
code = """
def calculate_area(length, width):
    area = length * width
    return area
"""

result = generator.generate_from_string(code)
print(result['docstring'])

# Generate from file
result = generator.generate_from_file('my_script.py')
print(result['documentation'])
```

### Web Interface

1. Open the Streamlit app in your browser
2. Choose to paste code or upload a Python file
3. Enter your Python function
4. Click "Generate Documentation"
5. Review and download the results

### Command Line

```bash
# Generate from code string
python doc_generator.py -s "def add(a, b): return a + b" -o docs.md

# Generate from file
python doc_generator.py my_script.py -o documentation.md
```

## ğŸ”§ System Components

### 1. DocumentationPipeline (`pipeline.py`)

Core pipeline that integrates all components:
- Loads trained BPE tokenizer, Word2Vec, and BiLSTM models
- Handles code preprocessing and tokenization
- Generates docstrings using the language model
- Provides unified interface for documentation generation

### 2. DocumentationGenerator (`doc_generator.py`)

High-level interface for documentation generation:
- Processes single functions or entire files
- Extracts functions from Python code
- Combines results into formatted documentation
- Handles errors gracefully

### 3. Streamlit UI (`streamlit_app.py`)

Interactive web interface:
- Upload files or paste code
- Real-time documentation generation
- Download generated documentation
- Model status and system information

## ğŸ“Š Features

### Input Methods
- âœ… Paste Python code directly
- âœ… Upload Python files (.py)
- âœ… Process multiple functions in a file
- âœ… Command line interface

### Output Formats
- âœ… Generated docstrings
- âœ… Function summaries
- âœ… Complete documentation (Markdown)
- âœ… Downloadable files

### AI Pipeline
- âœ… BPE tokenization for code preprocessing
- âœ… Word2Vec embeddings (optional enhancement)
- âœ… BiLSTM language model for text generation
- âœ… Configurable generation parameters

### Error Handling
- âœ… Syntax error detection
- âœ… Graceful fallbacks
- âœ… Detailed error messages
- âœ… Model loading validation

## ğŸ§ª Testing

Run the integration tests to validate the system:

```bash
cd integration
python test_integration.py
```

The test suite includes:
- Sample function processing
- File processing with multiple functions
- Error handling validation
- Model loading verification

## âš™ï¸ Configuration

### Model Paths
The system automatically looks for models in:
- `bilstm/bilstm_model.pt` - BiLSTM language model
- `bilstm/bpe_tokenizer.pkl` - BPE tokenizer
- `word2vec/word2vec_model.pt` - Word2Vec model (optional)

### Generation Parameters
- `max_length`: Maximum docstring length (default: 100)
- `device`: CUDA or CPU (auto-detected)
- `context_length`: Input context length (default: 20 tokens)

## ğŸ” Model Information

The system provides detailed model information:
- Device usage (CUDA/CPU)
- Model loading status
- Vocabulary size
- Model architecture details

## ğŸ“ Example Output

**Input:**
```python
def calculate_discount(price, discount_percent):
    discount_amount = price * (discount_percent / 100)
    final_price = price - discount_amount
    return final_price
```

**Generated Documentation:**
```markdown
# Function: calculate_discount

## Summary
Function 'calculate_discount' takes parameters: price, discount_percent

## Parameters
- `price`: Parameter description
- `discount_percent`: Parameter description

## Generated Docstring
"""
Calculate discount amount and final price
"""
```

## ğŸš¨ Troubleshooting

### Common Issues

1. **Models not found**: Ensure all model files are in correct directories
2. **CUDA errors**: System will fallback to CPU automatically
3. **Import errors**: Check Python path and dependencies
4. **Memory issues**: Reduce batch size or use CPU

### Debug Mode

Enable detailed error messages:
```python
generator = DocumentationGenerator()
result = generator.generate_from_string(code)
if result['status'] == 'error':
    print(result['traceback'])
```

## ğŸ”® Future Enhancements

- Support for more programming languages
- Advanced docstring templates
- Integration with IDEs
- Batch processing optimization
- Custom model fine-tuning

## ğŸ“„ License

This project is part of the GenerativeAI_Project educational system.
