{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff4b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenizer loaded | Vocab size: 1068\n",
      "üìÇ Checkpoint keys: dict_keys(['model_state_dict', 'vocab_size', 'model_config'])\n",
      "üîß Model config from checkpoint: {'embed_dim': 128, 'hidden_dim': 256, 'num_layers': 2}\n",
      "‚úÖ Model restored successfully on cpu\n",
      "\n",
      "üìä Model Perplexity: 1.24\n",
      "\n",
      "üìù Generated text sample:\n",
      "\n",
      "dobject.\"\"\"ifnot_______________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load dataset (small sample for test)\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"../data/clean_dataset.csv\")   # adjust path if needed\n",
    "sample_df = df.sample(100, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Reload Tokenizer\n",
    "# ----------------------------\n",
    "class BPETokenizer:\n",
    "    def __init__(self, vocab, merges=None):\n",
    "        self.vocab = vocab\n",
    "        self.word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "        self.idx_to_word = {i: w for w, i in self.word_to_idx.items()}\n",
    "        self.merges = merges or []\n",
    "\n",
    "    def encode(self, text):\n",
    "        return list(text)  # fallback: char-level\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \"\".join(tokens)\n",
    "\n",
    "# Load saved tokenizer\n",
    "with open(\"../bilstm/bpe_tokenizer.pkl\", \"rb\") as f:\n",
    "    tok_data = pickle.load(f)\n",
    "\n",
    "if isinstance(tok_data, dict):\n",
    "    tokenizer = BPETokenizer(\n",
    "        vocab=tok_data.get(\"vocab\", []),\n",
    "        merges=tok_data.get(\"merges\", [])\n",
    "    )\n",
    "else:\n",
    "    tokenizer = tok_data\n",
    "\n",
    "print(\"‚úÖ Tokenizer loaded | Vocab size:\", len(tokenizer.vocab))\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Reload Model\n",
    "# ----------------------------\n",
    "class BiLSTMLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=128, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, vocab_size)\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "checkpoint = torch.load(\"../bilstm/bilstm_model.pt\", map_location=device)\n",
    "print(\"üìÇ Checkpoint keys:\", checkpoint.keys())\n",
    "\n",
    "# Read model config from checkpoint\n",
    "config = checkpoint.get(\"model_config\", {})\n",
    "print(\"üîß Model config from checkpoint:\", config)\n",
    "\n",
    "# Build model with checkpoint config\n",
    "model = BiLSTMLM(\n",
    "    vocab_size=checkpoint[\"vocab_size\"],\n",
    "    embed_dim=config.get(\"embed_dim\", 100),\n",
    "    hidden_dim=config.get(\"hidden_dim\", 128),\n",
    "    num_layers=config.get(\"num_layers\", 2)\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "print(\"‚úÖ Model restored successfully on\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Perplexity Computation\n",
    "# ----------------------------\n",
    "def compute_perplexity(model, sequences, seq_len=20):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for seq in sequences[:200]:  # limit to 200 samples\n",
    "        idxs = [tokenizer.word_to_idx[t] for t in seq if t in tokenizer.word_to_idx]\n",
    "        for i in range(len(idxs) - seq_len):\n",
    "            X = torch.tensor(idxs[i:i+seq_len], dtype=torch.long).unsqueeze(0).to(device)\n",
    "            Y = torch.tensor(idxs[i+1:i+seq_len+1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(X)\n",
    "                loss = criterion(out.view(-1, len(tokenizer.vocab)), Y.view(-1))\n",
    "                losses.append(loss.item())\n",
    "    avg_loss = np.mean(losses)\n",
    "    return np.exp(avg_loss)\n",
    "\n",
    "# Encode dataset with tokenizer\n",
    "sequences = [tokenizer.encode(c) for c in sample_df['code'].astype(str)]\n",
    "ppl = compute_perplexity(model, sequences)\n",
    "print(f\"\\nüìä Model Perplexity: {ppl:.2f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Text Generation\n",
    "# ----------------------------\n",
    "def generate_text(model, start_token=\"d\", length=100):\n",
    "    model.eval()\n",
    "    tokens = [tokenizer.word_to_idx.get(start_token, 0)]\n",
    "    for _ in range(length):\n",
    "        inp = torch.tensor(tokens[-20:], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(inp)\n",
    "            next_token = torch.argmax(out[0, -1]).item()\n",
    "        tokens.append(next_token)\n",
    "    return tokenizer.decode([tokenizer.idx_to_word[i] for i in tokens])\n",
    "\n",
    "print(\"\\nüìù Generated text sample:\\n\")\n",
    "print(generate_text(model, start_token=\"d\", length=200))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
